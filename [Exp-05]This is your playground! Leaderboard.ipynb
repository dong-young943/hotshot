{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7465990",
   "metadata": {},
   "source": [
    "# 인공지능과 가위바위보 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa1aded",
   "metadata": {},
   "source": [
    "## 데이터를 준비하자!\n",
    "#### MNIST 숫자 손글씨 Dataset 불러들이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "777f86be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "print(tf.__version__)   # Tensorflow의 버전을 출력\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "# MNIST 데이터를 로드. 다운로드하지 않았다면 다운로드까지 자동으로 진행됩니다. \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()   \n",
    "\n",
    "print(len(x_train))  # x_train 배열의 크기를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f337eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.21.4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728c50b3",
   "metadata": {},
   "source": [
    "#### 데이터 불러오기 + Resize 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f0205d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eae0a619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebf6c685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca0e30de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "791cd798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a43f39bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a860a769",
   "metadata": {},
   "source": [
    "### 데이터 전처리 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0df09b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소값: 0  최대값: 255\n"
     ]
    }
   ],
   "source": [
    "print('최소값:',np.min(x_train), ' 최대값:',np.max(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72f751b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소값: 0.0  최대값: 1.0\n"
     ]
    }
   ],
   "source": [
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "print('최소값:',np.min(x_train_norm), ' 최대값:',np.max(x_train_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad8e5e0",
   "metadata": {},
   "source": [
    "## 딥러닝 네트워크 설계하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e1e3e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06574d86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Reshape - x_train_norm shape: (300, 28, 28, 3)\n",
      "Before Reshape - x_test_norm shape: (10000, 28, 28)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 7840000 into shape (28,28,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48/3247645291.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx_train_reshaped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx_test_reshaped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"After Reshape - x_train_reshaped shape: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_reshaped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 7840000 into shape (28,28,3)"
     ]
    }
   ],
   "source": [
    "print(\"Before Reshape - x_train_norm shape: {}\".format(x_train_norm.shape))\n",
    "print(\"Before Reshape - x_test_norm shape: {}\".format(x_test_norm.shape))\n",
    "\n",
    "x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 3)\n",
    "\n",
    "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape))\n",
    "print(\"After Reshape - x_test_reshaped shape: {}\".format(x_test_reshaped.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df326f0a",
   "metadata": {},
   "source": [
    "### 딥러닝 네트워크 학습시키기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35ee8168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 31s 22ms/step - loss: 1.0597 - accuracy: 0.4600\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9510 - accuracy: 0.6533\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7578 - accuracy: 0.8533\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.9200\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3244 - accuracy: 0.9500\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.9767\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1170 - accuracy: 0.9733\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8394cf5310>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9167d106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82f790a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1330 test_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1320 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1313 run_step  **\n        outputs = model.test_step(data)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1267 test_step\n        y_pred = self(x, training=False)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/input_spec.py:250 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 3 but received input with shape (None, 28, 28, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48/3286441066.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_loss: {} \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_accuracy: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 759\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    760\u001b[0m             *args, **kwds))\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1330 test_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1320 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1313 run_step  **\n        outputs = model.test_step(data)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1267 test_step\n        y_pred = self(x, training=False)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/input_spec.py:250 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 3 but received input with shape (None, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2b7731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회고\n",
    "#### 어려웠던 점 : 코드에 문제가 있는데 그것을 못알아내서 어려웠다.\n",
    "#### 알아낸 점 : CV가 대체로 어떻게 만들어지는지 알게 되었다.\n",
    "#### 시도한 것들 : 직접 사진 300장이상을 촬영해서 주피터클라우드에 업로드했다.\n",
    "#### if 달성하지 못했을 때, : \n",
    "#### 자기 다짐 : 나는 아무래도 CV보다 NLP가 맞는 거 같다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
